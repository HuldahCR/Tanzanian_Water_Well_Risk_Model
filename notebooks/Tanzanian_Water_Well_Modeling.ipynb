{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Water Security: Leveraging Data to Improve Well Reliability in Tanzania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Business Understanding\n",
    "\n",
    "## 1.1 Background\n",
    "Sub-Saharan Africa faces severe water scarcity, with over 400 million people lacking access to safe drinking water (UNICEF/WHO, 2023). Tanzania, like many Sub-Saharan African countries, faces significant water scarcity challenges with only about 55-60% of its rural population having access to clean and safe water sources. \n",
    "\n",
    "Rural communities depend heavily on hand pumps and boreholes with over **59,000 water points** being established across the country,yet many are unreliable: studies estimate that **30–40% of rural water wells are non-functional at any given time**. This unreliability undermines the efforts of governments, NGOs, and donors who invest heavily in rural water infrastructure.  \n",
    "\n",
    "The lack of reliable water access contributes to:  \n",
    "- Increased disease burden due to unsafe alternatives.  \n",
    "- Lost productivity, especially among women and children who spend hours fetching water.  \n",
    "- Strained agricultural productivity and rural economies.  \n",
    "- Incomplete achievement of UN Sustainable Development Goal 6 (Clean Water and Sanitation).  \n",
    "\n",
    "From prior research (World Bank, WASH studies, NGOs like WaterAid), common reasons for well failure or need for repairs include:\n",
    "\n",
    "- Mechanical breakdowns – pump handles, seals, rods, or cylinders wear out.\n",
    "- Poor construction quality – shallow wells collapse, improper casing, low-standard materials.\n",
    "- Water table variability – seasonal or climate-related drop in groundwater.\n",
    "- Poor community management – lack of funds, poor fee collection, or unclear ownership.\n",
    "- Environmental/geographical factors – saline water, iron contamination, or flooding.\n",
    "- Age of installation – older pumps naturally degrade without consistent maintenance.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2 Problem Statement\n",
    "The Government of Tanzania and development partners need to improve their ability to **predict and prevent water point failure**. Current monitoring systems are reactive and costly, often identifying broken wells only after communities are already suffering.  \n",
    "\n",
    "The problem is:  \n",
    "- How can we **predict the functionality status of wells** (functional, needs repair, non-functional) using available installation, geospatial, and technical features?  \n",
    "- How can we detect **patterns in geospatial and operational data** that influence well longevity and reliability?  \n",
    "\n",
    "---\n",
    "\n",
    "## 1.3 Objectives\n",
    "The objectives of this project are to:  \n",
    "1. **Predict well functionality status** (functional / needs repair / non-functional).  \n",
    "2. **Identify geospatial and operational patterns** associated with water point failure.  \n",
    "3. **Generate explainable insights** for decision-makers such as NGOs, government institutions, and funding agencies to inform repair prioritization and new well construction.  \n",
    "\n",
    "---\n",
    "## 1.4 Stakeholders\n",
    "The key stakeholders who will benefit from this analysis include:  \n",
    "- **Government of Tanzania (Ministry of Water & Rural Development):** For policy-making and allocation of resources.  \n",
    "- **Non-Governmental Organizations (NGOs):** To prioritize well repairs and improve project planning.  \n",
    "- **Funding Agencies & Donors (e.g., AfDB, World Bank, UNICEF):** For evidence-based investment decisions.  \n",
    "- **Local Communities:** To ensure consistent access to clean and reliable water.  \n",
    "- **Civil Engineers & Technicians:** To identify high-risk wells and improve future designs.  \n",
    "- **Researchers & Planners:** To analyze geospatial patterns and long-term sustainability.  \n",
    "\n",
    "---\n",
    "\n",
    "## 1.5 Metrics of Success\n",
    "The project will be considered successful if:  \n",
    "- A predictive model achieves at least **70% accuracy** in correctly classifying well status on unseen data.  \n",
    "- The model provides **interpretable feature importance** (e.g., pump type, construction year, funder) that aligns with engineering and field knowledge.  \n",
    "- Key geospatial clusters of high failure rates are detected and visualized.  \n",
    "- Actionable insights are delivered, enabling:  \n",
    "  - At least **20% reduction in repair costs** by prioritizing wells likely to fail.  \n",
    "  - Improved allocation of resources for preventive maintenance.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Understanding  \n",
    "\n",
    "The Data Understanding phase of the CRISP-DM process focuses on familiarizing with the dataset before conducting any modeling or advanced exploration. At this stage, the goal is to collect and describe the data, identify its structure, and assess overall quality.  \n",
    "\n",
    "For this project, the dataset comes from the **Tanzania Water Wells dataset**, originally made available through the Taarifa initiative and supported by the Tanzanian Ministry of Water. The data captures information on over 59,000 water points, including attributes such as pump type, installer, water source, geographical location, construction year, and the functional status of the well. The dataset has also been hosted on **DrivenData** as part of their open data challenges: [Tanzania Water Wells – DrivenData](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/). \n",
    "\n",
    "The dataset is provided in **CSV format**, making it easy to load and process using data science tools like Python (pandas, NumPy). It contains both categorical and numerical variables, as well as geospatial coordinates.  \n",
    "\n",
    "The key goals of this phase are to:  \n",
    "- Assess the **shape and structure** of the dataset (number of records, features, and data types).  \n",
    "- Evaluate **data completeness and consistency**, including missing values and duplicates.  \n",
    "- Begin forming early hypotheses about the quality of the data and potential preprocessing needs.  \n",
    "- Lay the groundwork for the Exploratory Data Analysis (EDA) phase, where deeper insights into patterns and distributions will be developed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a description of the main columns in the dataset drawn from the **DrivenData** website:\n",
    "\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "| **id** | Unique identifier for each water point (used for joining train/test/labels). |\n",
    "| **amount_tsh** | Total static head (in Tanzanian shillings), essentially the amount of water available if measured. |\n",
    "| **date_recorded** | Date when the data about the water point was recorded. |\n",
    "| **funder** | Name of the organization or individual who funded the well construction. |\n",
    "| **gps_height** | Altitude of the water point in meters above sea level. |\n",
    "| **installer** | Name of the organization or individual who installed the water point. |\n",
    "| **longitude** | Geographic coordinate (east-west position) of the water point. |\n",
    "| **latitude** | Geographic coordinate (north-south position) of the water point. |\n",
    "| **wpt_name** | Name of the water point (often specific to the community). |\n",
    "| **num_private** | Unknown — often blank or zero, possibly private connections. |\n",
    "| **basin** | Geographic water basin where the water point is located. |\n",
    "| **subvillage** | Name of the sub-village where the water point is located. |\n",
    "| **region** | Name of the region where the water point is located. |\n",
    "| **region_code** | Numeric code corresponding to the region (categorical identifier). |\n",
    "| **district_code** | Numeric code for the district (categorical identifier). |\n",
    "| **lga** | Local Government Area where the water point is located. |\n",
    "| **ward** | Ward where the water point is located. |\n",
    "| **population** | Population of the community served by the water point. |\n",
    "| **public_meeting** | Boolean (True/False) — whether a public meeting was held around the water point. |\n",
    "| **recorded_by** | Name of the agent/organization that recorded the data (usually `\"GeoData Consultants Ltd\"`). |\n",
    "| **scheme_management** | Entity responsible for managing the water point scheme (e.g., “village council”). |\n",
    "| **scheme_name** | Name of the water point management scheme. |\n",
    "| **permit** | Boolean (True/False) — whether the water point has a valid permit. |\n",
    "| **construction_year** | Year when the water point was constructed (can have missing or zero values). |\n",
    "| **extraction_type** | The kind of extraction method used (e.g., gravity, handpump). |\n",
    "| **extraction_type_group** | Grouped version of extraction_type (higher-level categories). |\n",
    "| **extraction_type_class** | Class-level version of extraction_type (simplest grouping). |\n",
    "| **management** | Who manages the water point (e.g., user group, water authority). |\n",
    "| **management_group** | Grouped version of management (simplified categories). |\n",
    "| **payment** | Payment method used (e.g., monthly, per bucket, free). |\n",
    "| **payment_type** | Simplified payment method categories. |\n",
    "| **water_quality** | Quality of the water (e.g., soft, salty, fluoride). |\n",
    "| **quality_group** | Simplified water quality categories. |\n",
    "| **quantity** | Quantity of water (e.g., enough, insufficient). |\n",
    "| **quantity_group** | Grouped quantity categories. |\n",
    "| **source** | Source of the water (e.g., spring, river, rainwater harvesting). |\n",
    "| **source_type** | Grouped version of source. |\n",
    "| **source_class** | High-level class of source (e.g., surface water, groundwater). |\n",
    "| **waterpoint_type** | Type of waterpoint (e.g., communal standpipe, handpump, cattle trough). |\n",
    "| **waterpoint_type_group** | Grouped version of waterpoint_type. |\n",
    "| **status_group** *(target)* | Functional status of the water point: **functional**, **functional needs repair**, or **non functional**. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for data cleaning\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot style\n",
    "plt.style.use(\"seaborn-whitegrid\") \n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\", palette=\"Set2\", font_scale=1.1)\n",
    "\n",
    "# hypothesis testing\n",
    "from scipy.stats import chi2_contingency,f_oneway\n",
    "\n",
    "\n",
    "# Modeling (scikit-learn)\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report, auc, roc_curve, roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from imblearn.over_sampling import SMOTE,SMOTEN\n",
    "\n",
    "# preprocessing and scaling\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "# Geospatial Analysis\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import folium\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Initial Data Exploration of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the X features dataset\n",
    "X_train_df = pd.read_csv(\"data/train_set.csv\")\n",
    "\n",
    "# preview the first 5 rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(X_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#preview the last 5 rows\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(X_train_df.tail())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation: The dataset values are uniform from top to bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train label dataset\n",
    "\n",
    "train_label_df = pd.read_csv(\"data/train_labels.csv\")\n",
    "\n",
    "# preview the first 5 rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(train_label_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the last 5 rows\n",
    "print(\"\\nlast 5 rows:\")\n",
    "display(train_label_df.tail())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation: The dataset values are uniform from top to bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the two datasets\n",
    "\n",
    "train_df = X_train_df.merge(train_label_df, on =\"id\")\n",
    "\n",
    "# preview the first 5 rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the last 5 rows\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(train_df.tail())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation: The merged dataset is uniform from top to bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape\n",
    "\n",
    "print(f\"The dataset has {train_df.shape[0]} records and {train_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the summary information\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation: \n",
    "1. The dataset comprises of 10 numerical and 31 categorical columns.\n",
    "2. The construction year is in numerical datatype but should be changed to datetime\n",
    "3. The date recorded can also be converted to datetime.\n",
    "4. We note that there are missing values in permit,scheme_name,scheme_management,public_meeting,sub-village,installer and funder which will need to be handled in the data preparation phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the summary statistics for numerical features\n",
    "train_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the summary statistics for categorical features\n",
    "train_df.describe(include=\"O\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Initial Data Exploration of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test dataset\n",
    "test_df = pd.read_csv(\"data/test_set.csv\")\n",
    "\n",
    "# preview the first 5 rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#preview the last 5 rows\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(test_df.tail())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation: The dataset values are uniform from top to bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape\n",
    "\n",
    "print(f\"The dataset has {test_df.shape[0]} records and {test_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the summary information\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation: \n",
    "1. The dataset comprises of 10 numerical and 30 categorical columns. It lacks the target variable given it is what will be used for evaluating the final model on unseen data.\n",
    "2. We note that it aligns with the training data where it has the same columns, formats and datatypes. It also has the same columns with missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation\n",
    "\n",
    "Following our data understanding phase, we now transition into the Data Preparation Stage of the CRISP-DM methodology. This phase is crucial in transforming raw data into a clean and structured format that can be used effectively in analysis and modeling.\n",
    "\n",
    "This section includes:\n",
    "1. Selection of relevant data\n",
    "2. Data Cleaning\n",
    "3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data Cleaning\n",
    "\n",
    "In this stage, we focus on preparing the raw dataset for analysis and modeling.  \n",
    "The main goals are:  \n",
    "\n",
    "- Handle missing and invalid values.  \n",
    "- Ensure correct data types.  \n",
    "- Standardize categorical values to reduce noise.  \n",
    "- Remove duplicates (if any).  \n",
    "- Create consistent, analysis-ready features.  \n",
    "\n",
    "This ensures that the data used in later stages is accurate, reliable, and suitable for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Data Cleaning of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a copy of the original df\n",
    "\n",
    "train_df1 = train_df.copy(deep=True)\n",
    "\n",
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date recorded to date time\n",
    "train_df1['date_recorded'] = pd.to_datetime(train_df1['date_recorded'])\n",
    "\n",
    "train_df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert construction_year = 0 to NaN (not realistic)\n",
    "train_df1['construction_year'] = train_df1['construction_year'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning latitude(ranges between -12 and 0) and longitude(ranges between 29 and 41) for Tanzania\n",
    "\n",
    "# Replace 0.0 values with NaN\n",
    "train_df1['latitude'] = train_df1['latitude'].replace(0, np.nan)\n",
    "train_df1['longitude'] = train_df1['longitude'].replace(0, np.nan)\n",
    "\n",
    "# Drop values outside Tanzania bounds \n",
    "train_df1.loc[(train_df1['latitude'] > 0) | (train_df1['latitude'] < -12), 'latitude'] = np.nan\n",
    "train_df1.loc[(train_df1['longitude'] < 29) | (train_df1['longitude'] > 41), 'longitude'] = np.nan\n",
    "\n",
    "# Check\n",
    "train_df1[['latitude', 'longitude']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check summary statistics again\n",
    "train_df1.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning gps height as an elevation of 0 means that the well is at the sea level\n",
    "\n",
    "# Only set to NaN if the well is inland (not coastal regions)\n",
    "coastal_regions = [\"pwani\", \"lindi\", \"mtwara\", \"tanga\", \"dar es salaam\"]\n",
    "\n",
    "train_df1.loc[(train_df1[\"gps_height\"] == 0) & (~train_df1[\"region\"].isin(coastal_regions)), \"gps_height\"] = np.nan\n",
    "\n",
    "\n",
    "if train_df1[\"gps_height\"].isna().any():\n",
    "    train_df1[\"gps_height\"] = train_df1.groupby(\"region\")[\"gps_height\"].transform(\n",
    "            lambda x: x.fillna(x.median()))\n",
    "\n",
    "# fill remaining null values with median\n",
    "train_df1[\"gps_height\"] = train_df1[\"gps_height\"].fillna(train_df1[\"gps_height\"].median())\n",
    "\n",
    "#check for null values\n",
    "train_df1[\"gps_height\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for unique values\n",
    "for col in train_df1.select_dtypes(include='object').columns:\n",
    "    print(f\"\\n--- {col.upper()} ---\")\n",
    "    print(train_df1[col].value_counts(dropna=False).head(20))  # show top 20\n",
    "    print(\"Unique values:\", train_df1[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a function to clean categorical columns\n",
    "def clean_text(s):\n",
    "    if pd.isna(s):\n",
    "        return np.nan\n",
    "    # strip whitespace and convert to lowercase\n",
    "    s = str(s).strip().lower()\n",
    "    # treat textual '0' or 'none' like missing in messy columns\n",
    "    if s in {\"\", \"0\", \"none\", \"na\", \"n/a\", \"nan\", \"null\", \"-\"}:\n",
    "        return np.nan\n",
    "    s = re.sub(r\"\\s+\", \" \", s)        # collapse spaces\n",
    "    s = re.sub(r\"[^\\w\\s&/+-]\", \"\", s) # strip punctuation except useful symbols\n",
    "    return s\n",
    "\n",
    "cat_cols = train_df1.select_dtypes(include=\"O\")\n",
    "\n",
    "for col in cat_cols:\n",
    "    if col in train_df1.columns:\n",
    "        train_df1[col] = train_df1[col].apply(clean_text)\n",
    "\n",
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "train_df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check for unique values\n",
    "for col in train_df1.select_dtypes(include='object').columns:\n",
    "    print(f\"\\n--- {col.upper()} ---\")\n",
    "    print(train_df1[col].value_counts(dropna=False).head(20))  # show top 20\n",
    "    print(\"Unique values:\", train_df1[col].nunique())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation: \n",
    "\n",
    "We note that there are highly redundant columns which introduce noise. \n",
    "1. Extraction: extraction_type (18), extraction_type_group (13), extraction_type_class (7).\n",
    "- Best to keep extraction_type_class (7 levels) — simplest representation.\n",
    "\n",
    "2. Management: management (12) vs. management_group (5).\n",
    "- Keep management_group (5 levels).\n",
    "\n",
    "3. Payment: payment (7) vs. payment_type (7).\n",
    "- They are basically duplicates. Keep payment_type.\n",
    "\n",
    "4. Water quality: water_quality (8) vs. quality_group (6).\n",
    "- Keep quality_group.\n",
    "\n",
    "5. Quantity: quantity (5) vs. quantity_group (5).\n",
    "- Keep quantity_group.\n",
    "\n",
    "6. Source: source (10), source_type (7), source_class (3).\n",
    "- Best to keep source_class (3).\n",
    "\n",
    "7. Waterpoint type: waterpoint_type (7) vs. waterpoint_type_group (6).\n",
    "- Keep waterpoint_type_group.\n",
    "\n",
    "We also not that there are categorical columns with a huge number of unique values as follows:\n",
    "1. funder (1,895 unique) & installer (1,903 unique)\n",
    "- Has many misspellings and rare categories.\n",
    "- We can normalize → keep Top 20 buckets → others = \"other\".\n",
    "\n",
    "2. wpt_name (37,369 unique) & subvillage (19,245 unique). \n",
    "- Too many unique values, will blow up one-hot encoding.\n",
    "- We can drop this as it is not useful for predictive models.\n",
    "\n",
    "3. scheme_name (2,522 unique) with ~48% missing\n",
    "- We can drop this and keep scheme_management instead.\n",
    "\n",
    "4. ward (2,092 unique)\n",
    "- drop as region/lga are present with fewer unique values.\n",
    "\n",
    "We also note that recorded_by has only 1 unique value (“Geodata Consultants Ltd”) hence we can drop this column as it does not add any insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = [\n",
    "    \"id\",\"wpt_name\", \"subvillage\", \"scheme_name\", \"ward\", \"recorded_by\",\n",
    "    \"extraction_type\", \"extraction_type_group\",   # keep class\n",
    "    \"management\",                                 # keep group\n",
    "    \"payment\",                                    # keep type\n",
    "    \"water_quality\",                              # keep quality_group\n",
    "    \"quantity\",                                   # keep quantity_group\n",
    "    \"source\", \"source_type\",                      # keep source_class\n",
    "    \"waterpoint_type\"                             # keep waterpoint_type_group\n",
    "]\n",
    "\n",
    "train_df1 = train_df1.drop(columns=col_to_drop, errors=\"coerce\")\n",
    "\n",
    "train_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funder dictionary\n",
    "funder_map = {\n",
    "    \"central government\":\"government\",\"goverment\":\"government\",\"gok\":\"government\",\"gov\":\"government\",\n",
    "    \"world visio\":\"world vision\",\"worldvision\":\"world vision\",\n",
    "    \"danid\":\"danida\",\"daninda\":\"danida\",\n",
    "    \"germany republi\":\"german republic\",\n",
    "    \"ministry of water\":\"ministry of water\",\n",
    "    \"district council\":\"district council\",\n",
    "    \"private individual\":\"private individual\",\n",
    "    \"rwssp\":\"rwssp\",\"hesawa\":\"hesawa\",\"tcrs\":\"tcrs\",\"kkkt\":\"kkkt\",\n",
    "    \"unicef\":\"unicef\",\"norad\":\"norad\",\"dhv\":\"dhv\",\"tasaf\":\"tasaf\",\"world bank\":\"world bank\"\n",
    "}\n",
    "\n",
    "\n",
    "#map the dictionary to the funders\n",
    "train_df1[\"funder\"] = train_df1[\"funder\"].replace(funder_map)\n",
    "\n",
    "train_df1[\"funder\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installer dictionary\n",
    "installer_map = {\n",
    "    \"central government\":\"government\",\"goverment\":\"government\",\"gok\":\"government\",\n",
    "    \"world visio\":\"world vision\",\"worldvision\":\"world vision\",\n",
    "    \"danid\":\"danida\",\"daninda\":\"danida\",\n",
    "    \"kkkt\":\"kkkt\",\"dwe\":\"dwe\",\"rwe\":\"rwe\",\n",
    "    \"district council\":\"district council\",\"tcrs\":\"tcrs\",\"hesawa\":\"hesawa\"\n",
    "}\n",
    "\n",
    "train_df1[\"installer\"] = train_df1[\"installer\"].replace(installer_map)\n",
    "\n",
    "train_df1[\"installer\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values again\n",
    "train_df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fill missing values for categorical columns with \"unknown\"\n",
    "\n",
    "for col in [\"funder\", \"installer\", \"scheme_management\"]:\n",
    "    train_df1[col] = train_df1[col].fillna(\"unknown\")\n",
    "    \n",
    "#check for missing values\n",
    "train_df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute null values for longitude with the regional median longitude\n",
    "if train_df1[\"longitude\"].isna().any():\n",
    "    train_df1[\"longitude\"] = train_df1.groupby(\"region\")[\"longitude\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "#check null values\n",
    "train_df1[\"longitude\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute null values for construction year with the regional median construction year\n",
    "if train_df1[\"construction_year\"].isna().any():\n",
    "    train_df1[\"construction_year\"] = train_df1.groupby(\"region\")[\"construction_year\"].transform(\n",
    "            lambda s: s.fillna(s.median()))\n",
    "\n",
    "# impute remaining nulls with the median construction year\n",
    "train_df1[\"construction_year\"] = train_df1[\"construction_year\"].fillna(train_df1[\"construction_year\"].median())\n",
    "\n",
    "#check for null values\n",
    "train_df1[\"construction_year\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to fill with the mode for public meeting and permit\n",
    "def fill_mode(group):\n",
    "        mode = group.mode(dropna=True)\n",
    "        return group.fillna(mode.iloc[0] if not mode.empty else \"unknown\")\n",
    "    \n",
    "# apply the function to imputing the permit by region\n",
    "train_df1[\"permit\"] = train_df1.groupby(\"region\")[\"permit\"].transform(fill_mode)\n",
    "\n",
    "# check for null values\n",
    "train_df1[\"permit\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to imputing the public meeting by region\n",
    "train_df1[\"public_meeting\"] = train_df1.groupby(\"region\")[\"public_meeting\"].transform(fill_mode)\n",
    "\n",
    "# check for null values\n",
    "train_df1[\"public_meeting\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "train_df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "train_df1.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for outliers\n",
    "sns.boxplot(train_df1)\n",
    "plt.tight_layout()\n",
    "plt.grid(alpha=.3)\n",
    "plt.xticks(rotation=45)\n",
    ";"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation: \n",
    "We have outliers but they are genuine hence will be retained in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1.1 Feature Engineering of Train Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column for the year of record\n",
    "train_df1[\"recorded_year\"] = train_df1[\"date_recorded\"].dt.year\n",
    "\n",
    "#create a new column for age of the wells at the time of recording\n",
    "train_df1[\"age_years\"] = train_df1[\"recorded_year\"] - train_df1[\"construction_year\"]\n",
    "\n",
    "#check the head \n",
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create bins for the age years(categorical)\n",
    "train_df1[\"age_bin\"] = pd.cut(\n",
    "        train_df1[\"age_years\"],\n",
    "        bins=[-1, 5, 15, 30, 80],\n",
    "        labels=[\"0-5\", \"6-15\", \"16-30\",\"30+\"]\n",
    "    ).astype(\"category\")\n",
    "\n",
    "# check the first 5 rows\n",
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create elevation bins\n",
    "train_df1[\"elevation_bin\"] = pd.cut(\n",
    "    train_df1[\"gps_height\"],\n",
    "    bins=[-100, 500, 1000, 1500, 2500, 6000],\n",
    "    labels=[\"lowland (<500m)\", \"lower midland (500-1000m)\", \"upper midland (1000-1500m)\", \n",
    "            \"highland (1500-2500m)\", \"extreme highland (>2500m)\"]\n",
    ").astype(\"category\")\n",
    "\n",
    "# check the first 5 rows\n",
    "train_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function for bucketing\n",
    "\n",
    "def top_n_bucket(series, n=20, other = \"other\"):\n",
    "    top = series.value_counts().nlargest(n).index\n",
    "    return series.where(series.isin(top), other)\n",
    "\n",
    "# apply function to the funder column and create a new column\n",
    "train_df1[\"funder_bkt\"] = top_n_bucket(train_df1[\"funder\"],n=20)\n",
    "\n",
    "#apply function to the installer column and create a new column\n",
    "train_df1[\"installer_bkt\"] = top_n_bucket(train_df1[\"installer\"], n=20)\n",
    "\n",
    "#check the unique value counts\n",
    "\n",
    "train_df1[\"funder_bkt\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the unique value counts\n",
    "\n",
    "train_df1[\"installer_bkt\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping regions → zones\n",
    "region_zone_map = {\n",
    "    \"dar es salaam\": \"coastal\",\n",
    "    \"pwani\": \"coastal\",\n",
    "    \"tanga\": \"coastal\",\n",
    "    \"lindi\": \"coastal\",\n",
    "    \"mtwara\": \"coastal\",\n",
    "\n",
    "    \"mwanza\": \"lake_basin\",\n",
    "    \"kagera\": \"lake_basin\",\n",
    "    \"mara\": \"lake_basin\",\n",
    "    \"shinyanga\": \"lake_basin\",\n",
    "    \"tabora\": \"lake_basin\",\n",
    "\n",
    "    \"arusha\": \"northern_highlands\",\n",
    "    \"kilimanjaro\": \"northern_highlands\",\n",
    "    \"manyara\": \"northern_highlands\",\n",
    "\n",
    "    \"iringa\": \"southern_highlands\",\n",
    "    \"mbeya\": \"southern_highlands\",\n",
    "    \"ruvuma\": \"southern_highlands\",\n",
    "    \"rukwa\": \"southern_highlands\",\n",
    "    \"njombe\": \"southern_highlands\",\n",
    "    \n",
    "    \"dodoma\": \"central\",\n",
    "    \"singida\": \"central\"\n",
    "}\n",
    "\n",
    "# Create new column\n",
    "train_df1[\"region_zone\"] = train_df1[\"region\"].map(region_zone_map).fillna(\"other\")\n",
    "\n",
    "# Quick check\n",
    "print(train_df1[\"region_zone\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned train dataset\n",
    "train_df1.to_csv(\"data/train_clean.csv\", index=False)\n",
    "\n",
    "print(\"✅ Cleaned datasets saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Data Cleaning of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the original test df\n",
    "\n",
    "test_df1 = test_df.copy(deep=True)\n",
    "\n",
    "test_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the columns\n",
    "test_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date recorded to date time\n",
    "test_df1['date_recorded'] = pd.to_datetime(test_df1['date_recorded'])\n",
    "\n",
    "test_df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert construction_year = 0 to NaN (not realistic)\n",
    "test_df1['construction_year'] = test_df1['construction_year'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning latitude(ranges between -12 and 0) and longitude(ranges between 29 and 41) for Tanzania\n",
    "\n",
    "# Replace 0.0 values with NaN\n",
    "test_df1['latitude'] = test_df1['latitude'].replace(0, np.nan)\n",
    "test_df1['longitude'] = test_df1['longitude'].replace(0, np.nan)\n",
    "\n",
    "# Drop values outside Tanzania bounds \n",
    "test_df1.loc[(train_df1['latitude'] > 0) | (test_df1['latitude'] < -12), 'latitude'] = np.nan\n",
    "test_df1.loc[(train_df1['longitude'] < 29) | (test_df1['longitude'] > 41), 'longitude'] = np.nan\n",
    "\n",
    "# Check\n",
    "test_df1[['latitude', 'longitude']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check summary statistics again\n",
    "test_df1.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning gps height as an elevation of 0 means that the well is at the sea level\n",
    "\n",
    "# Only set to NaN if the well is inland (not coastal regions)\n",
    "test_df1.loc[(test_df1[\"gps_height\"] == 0) & (~test_df1[\"region\"].isin(coastal_regions)), \"gps_height\"] = np.nan\n",
    "\n",
    "\n",
    "if test_df1[\"gps_height\"].isna().any():\n",
    "    test_df1[\"gps_height\"] = test_df1.groupby(\"region\")[\"gps_height\"].transform(\n",
    "            lambda x: x.fillna(x.median()))\n",
    "\n",
    "# fill remaining null values with median\n",
    "test_df1[\"gps_height\"] = test_df1[\"gps_height\"].fillna(test_df1[\"gps_height\"].median())\n",
    "\n",
    "#check for null values\n",
    "test_df1[\"gps_height\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for unique values\n",
    "for col in test_df1.select_dtypes(include='object').columns:\n",
    "    print(f\"\\n--- {col.upper()} ---\")\n",
    "    print(test_df1[col].value_counts(dropna=False).head(20))  # show top 20\n",
    "    print(\"Unique values:\", test_df1[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clean the categorical columns using the clean_text function\n",
    "cat_cols = test_df1.select_dtypes(include=\"O\")\n",
    "\n",
    "for col in cat_cols:\n",
    "    if col in test_df1.columns:\n",
    "        test_df1[col] = test_df1[col].apply(clean_text)\n",
    "\n",
    "test_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "test_df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check for unique values\n",
    "for col in test_df1.select_dtypes(include='object').columns:\n",
    "    print(f\"\\n--- {col.upper()} ---\")\n",
    "    print(test_df1[col].value_counts(dropna=False).head(20))  # show top 20\n",
    "    print(\"Unique values:\", test_df1[col].nunique())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation: \n",
    "\n",
    "We note that there are highly redundant columns which introduce noise. \n",
    "1. Extraction: extraction_type (18), extraction_type_group (13), extraction_type_class (7).\n",
    "- Best to keep extraction_type_class (7 levels) — simplest representation.\n",
    "\n",
    "2. Management: management (12) vs. management_group (5).\n",
    "- Keep management_group (5 levels).\n",
    "\n",
    "3. Payment: payment (7) vs. payment_type (7).\n",
    "- They are basically duplicates. Keep payment_type.\n",
    "\n",
    "4. Water quality: water_quality (8) vs. quality_group (6).\n",
    "- Keep quality_group.\n",
    "\n",
    "5. Quantity: quantity (5) vs. quantity_group (5).\n",
    "- Keep quantity_group.\n",
    "\n",
    "6. Source: source (10), source_type (7), source_class (3).\n",
    "- Best to keep source_class (3).\n",
    "\n",
    "7. Waterpoint type: waterpoint_type (7) vs. waterpoint_type_group (6).\n",
    "- Keep waterpoint_type_group.\n",
    "\n",
    "We also not that there are categorical columns with a huge number of unique values as follows:\n",
    "1. funder (1,895 unique) & installer (1,903 unique)\n",
    "- Has many misspellings and rare categories.\n",
    "- We can normalize → keep Top 20 buckets → others = \"other\".\n",
    "\n",
    "2. wpt_name (37,369 unique) & subvillage (19,245 unique). \n",
    "- Too many unique values, will blow up one-hot encoding.\n",
    "- We can drop this as it is not useful for predictive models.\n",
    "\n",
    "3. scheme_name (2,522 unique) with ~48% missing\n",
    "- We can drop this and keep scheme_management instead.\n",
    "\n",
    "4. ward (2,092 unique)\n",
    "- drop as region/lga are present with fewer unique values.\n",
    "\n",
    "We also note that recorded_by has only 1 unique value (“Geodata Consultants Ltd”) hence we can drop this column as it does not add any insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1 = test_df1.drop(columns=col_to_drop, errors=\"coerce\")\n",
    "\n",
    "test_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map the funder dictionary to the funders\n",
    "test_df1[\"funder\"] = test_df1[\"funder\"].replace(funder_map)\n",
    "\n",
    "test_df1[\"funder\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use installer map to standardise the installers\n",
    "test_df1[\"installer\"] = test_df1[\"installer\"].replace(installer_map)\n",
    "\n",
    "test_df1[\"installer\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values again\n",
    "test_df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fill missing values for categorical columns with \"unknown\"\n",
    "\n",
    "for col in [\"funder\", \"installer\", \"scheme_management\"]:\n",
    "    test_df1[col] = test_df1[col].fillna(\"unknown\")\n",
    "    \n",
    "#check for missing values\n",
    "test_df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute null values for longitude with the regional median longitude\n",
    "if test_df1[\"longitude\"].isna().any():\n",
    "    test_df1[\"longitude\"] = test_df1.groupby(\"region\")[\"longitude\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "#check null values\n",
    "test_df1[\"longitude\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute null values for construction year with the regional median construction year\n",
    "if test_df1[\"construction_year\"].isna().any():\n",
    "    test_df1[\"construction_year\"] = test_df1.groupby(\"region\")[\"construction_year\"].transform(\n",
    "            lambda s: s.fillna(s.median()))\n",
    "\n",
    "# impute remaining nulls with the median construction year\n",
    "test_df1[\"construction_year\"] = test_df1[\"construction_year\"].fillna(train_df1[\"construction_year\"].median())\n",
    "\n",
    "#check for null values\n",
    "test_df1[\"construction_year\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function fill mode to impute the permit by region\n",
    "test_df1[\"permit\"] = test_df1.groupby(\"region\")[\"permit\"].transform(fill_mode)\n",
    "\n",
    "# check for null values\n",
    "test_df1[\"permit\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to imputing the public meeting by region\n",
    "test_df1[\"public_meeting\"] = test_df1.groupby(\"region\")[\"public_meeting\"].transform(fill_mode)\n",
    "\n",
    "# check for null values\n",
    "test_df1[\"public_meeting\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "test_df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "test_df1.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "test_df1.drop_duplicates(inplace=True)\n",
    "\n",
    "# check for duplicates\n",
    "test_df1.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for outliers\n",
    "sns.boxplot(test_df1)\n",
    "plt.tight_layout()\n",
    "plt.grid(alpha=.3)\n",
    "plt.xticks(rotation=45)\n",
    ";"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observation: \n",
    "We have outliers but they are genuine hence will be retained in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2.1 Feature Engineering of Test Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column for the year of record\n",
    "test_df1[\"recorded_year\"] = test_df1[\"date_recorded\"].dt.year\n",
    "\n",
    "#create a new column for age of the wells at the time of recording\n",
    "test_df1[\"age_years\"] = test_df1[\"recorded_year\"] - test_df1[\"construction_year\"]\n",
    "\n",
    "#check the head \n",
    "test_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create bins for the age years(categorical)\n",
    "test_df1[\"age_bin\"] = pd.cut(\n",
    "        train_df1[\"age_years\"],\n",
    "        bins=[-1, 5, 15, 30, 80],\n",
    "        labels=[\"0-5\", \"6-15\", \"16-30\",\"30+\"]\n",
    "    ).astype(\"category\")\n",
    "\n",
    "# check the first 5 rows\n",
    "test_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create elevation bins\n",
    "test_df1[\"elevation_bin\"] = pd.cut(\n",
    "    test_df1[\"gps_height\"],\n",
    "    bins=[-100, 500, 1000, 1500, 2500, 6000],\n",
    "    labels=[\"lowland (<500m)\", \"lower midland (500-1000m)\", \"upper midland (1000-1500m)\", \n",
    "            \"highland (1500-2500m)\", \"extreme highland (>2500m)\"]\n",
    ").astype(\"category\")\n",
    "\n",
    "# check the first 5 rows\n",
    "test_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function to the funder column and create a new column\n",
    "test_df1[\"funder_bkt\"] = top_n_bucket(test_df1[\"funder\"],n=20)\n",
    "\n",
    "#apply function to the installer column and create a new column\n",
    "test_df1[\"installer_bkt\"] = top_n_bucket(test_df1[\"installer\"], n=20)\n",
    "\n",
    "#check the unique value counts\n",
    "\n",
    "test_df1[\"funder_bkt\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the unique value counts\n",
    "\n",
    "test_df1[\"installer_bkt\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping regions → zones\n",
    "# Create new column using region zone map\n",
    "test_df1[\"region_zone\"] = test_df1[\"region\"].map(region_zone_map).fillna(\"other\")\n",
    "\n",
    "# Quick check\n",
    "print(test_df1[\"region_zone\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned test dataset\n",
    "\n",
    "test_df1.to_csv(\"data/test_clean.csv\", index = False)\n",
    "\n",
    "print(\"✅ Cleaned datasets saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploratory Data Analysis(EDA)\n",
    "\n",
    "Exploratory Data Analysis (EDA) is a critical step in understanding the Tanzania water wells dataset. The aim is not just to summarize the data, but to uncover patterns, trends, and relationships that can explain why some wells are functional while others fail.\n",
    "\n",
    "Through this process, we will:\n",
    "\n",
    "- Understand the distribution of our target variable (status_group).\n",
    "\n",
    "- Explore geospatial, technical, operational, and demographic factors.\n",
    "\n",
    "- Identify which features are most strongly associated with well reliability.\n",
    "\n",
    "- Generate hypotheses that can guide modeling and business recommendations.\n",
    "\n",
    "EDA will therefore bridge the gap between the business problem — unreliable rural water points — and the analytical solution, ensuring our model outputs are interpretable and actionable for stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Numerical Columns Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a df of numerical columns\n",
    "num_cols = train_df1.select_dtypes(include=\"number\")\n",
    "\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualise the numerical columns using a histogram\n",
    "\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.histplot(train_df1[col], kde=True, bins=30, color=\"skyblue\")\n",
    "    plt.title(f'Distribution of {col}', fontsize=14)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Univariate Analysis of Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2.1 Univariate Analysis of the Distribution of Well Functionality (Label/Target Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a pie chart of the functional status of \n",
    "label = [\"functional\", \"non functional\", \"functional needs repair\"]\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.pie(train_df1[\"status_group\"].value_counts(), labels=label, autopct=\" %.2f%%\")\n",
    "plt.title(\"Distribution of Well Functionality\", fontsize = 16)\n",
    "plt.tight_layout\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "More than 45% of wells are not fully reliable (either broken or in need of repair).\n",
    "\n",
    "This aligns with prior research that 30–40% of rural water wells in Sub-Saharan Africa are non-functional at any given time.\n",
    "\n",
    "The “needs repair” group is relatively small but important: these wells are at risk of becoming non-functional if maintenance is not done quickly.\n",
    "\n",
    "This imbalance shows that while the majority of wells work, there is still a significant water security challenge, justifying predictive modeling.\n",
    "\n",
    "The predictive model must handle a class imbalance problem, since \"functional needs repair\" is a small but critical class (only ~7%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2.2 Univariate analysis of X features categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    \"funder_bkt\", \"installer_bkt\", \"region\", \"region_zone\", \"basin\",\n",
    "    \"management_group\", \"payment_type\", \"quality_group\", \"quantity_group\",\n",
    "    \"source_class\", \"waterpoint_type_group\", \"permit\", \"public_meeting\"\n",
    "]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.countplot(data=train_df1, y=col, order=train_df1[col].value_counts().index)\n",
    "    plt.title(f\"Distribution of {col}\", fontsize=18)\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation and Interpretation\n",
    "\n",
    "1. Majority of the wells have a permit and there was a public meeting held indicating presence of good governance measures\n",
    "2. Majority of the waterpoints are the communal standpipes, followed by hand pumps and others\n",
    "3. Majority of the wells source of water is groundwater as opposed to surface water hence needing to ensure groundwater table is not exploited beyond replenishment.\n",
    "4. Majority of the wells provide enough water as per the demand followed by a considerable quantity producing insufficient water to meet the demand. This may be strongly related to functionality.\n",
    "5. Majority of the wells have good quality water. However, there are some with poor quality(salty,milky,colored,fluoride) which could be linked to failures.\n",
    "6. Majority of the wells lack a payment system. Payment schemes could influence sustainability.\n",
    "7. The vast majority of wells are managed by a user group which could be predictive.\n",
    "8. Distribution of the wells in the regions/zones/water basins is fairly balanced with Lake Zones and Coastal Zones dominating.\n",
    "9. Other funders and installers combined dominate in numbers indicating presence of smaller NGOs implementing and funding construction of wells as opposed to the top funders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Bivariate Analysis\n",
    "\n",
    "The aim is to check how different factors affect the reliability/functionality of the wells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Infrastructure and Technical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1.1 Relationship between the type of waterpoint and thefunctionality status of the well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(data=train_df1, x=\"waterpoint_type_group\", hue=\"status_group\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Functionality by Waterpoint Type\", fontsize=16)\n",
    "plt.xlabel(\"Type of waterpoint\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Communal standpipes and hand pumps dominate. Both have large numbers of non-functional wells. Improved springs and dams are rare.\n",
    "\n",
    "**Interpretation**: Since communal standpipes serve many people, their failures represent a big community risk. Preventive maintenance on these should be prioritized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1.2 Relationship between the type of extraction and the functionality status of the well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(data=train_df1, x=\"extraction_type_class\", hue=\"status_group\")\n",
    "plt.title(\"Functionality by Extraction Type\", fontsize=16)\n",
    "plt.xlabel(\"Type of Extraction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Gravity-fed systems are the most common and relatively reliable. Submersibles and handpumps also feature prominently. Motorpumps show a higher share of non-functional.\n",
    "\n",
    "**Interpretation**: Technology choice matters. Motorpumps and “other” extraction types may have sustainability issues. NGOs and government should evaluate durability before funding new installations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1.3 Relationship between the age of the well and the functionality status of the well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.histplot(data=train_df1, x=\"age_years\", bins=30, hue=\"status_group\", multiple=\"stack\")\n",
    "plt.title(\"Age of Wells vs Functionality\", fontsize=16)\n",
    "plt.xlabel(\"Age of Wells\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Wells under ~10 years dominate, but older wells show a higher share of non-functionality.\n",
    "\n",
    "**Interpretation**: As expected, older wells degrade over time. Maintenance strategies should focus on wells aged 15+ years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Governance and Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2.1 Relationship between Management Group of Wells and the Functionality Status of the Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(data=train_df1, x=\"management_group\", hue=\"status_group\")\n",
    "plt.title(\"Functionality by Management Group\", fontsize=16)\n",
    "plt.xlabel(\"Wells Management Group\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: “User-group” dominates, but even within this category many wells are non-functional. Commercial, parastatal, and other management groups have smaller representation.\n",
    "\n",
    "**Interpretation**: Community-based management is the norm but not always effective. This highlights the need for capacity building and governance support for user-groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2.2 Relationship between Availability of Permits and Functionality Status of Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(data=train_df1, x=\"permit\", hue=\"status_group\")\n",
    "plt.title(\"Functionality by Permit\", fontsize=16)\n",
    "plt.xlabel(\"Availability of Permit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Wells with permits are more often functional, but many permitted wells are still non-functional.\n",
    "\n",
    "**Interpretation**: Permits are helpful but not sufficient. They may reflect stronger oversight, but compliance/quality enforcement is uneven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2.3 Relationship between attendance of a public meeting at the waterpoint and the Functionality Status of Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(data=train_df1, x=\"public_meeting\", hue=\"status_group\")\n",
    "plt.title(\"Functionality by Management Group\", fontsize=16)\n",
    "plt.xlabel(\"Attendance of Public Meeting\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Wells in areas reporting public meetings are more functional, though still with substantial failures.\n",
    "\n",
    "**Interpretation**: Community governance has a positive influence, but it doesn’t guarantee reliability. Public participation matters, but must be paired with funding and training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Financial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3.1 Top 10 Funders by Functionality Status of Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_funders = train_df1[\"funder_bkt\"].value_counts().nlargest(10).index\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(data=train_df1[train_df1[\"funder_bkt\"].isin(top_funders)], x=\"funder_bkt\", hue=\"status_group\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Functionality by Top Funders\", fontsize=16)\n",
    "plt.xlabel(\"Top 10 Funders\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: “Other” dominates (many small/unknown funders). Larger organizations (Gov’t of Tanzania, World Bank, UNICEF) show mixed reliability.\n",
    "\n",
    "**Interpretation**: Smaller/unknown funders may deliver inconsistent quality. Big donors should monitor contractors and sustainability more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3.2 Top 10 Installers by Functionality Status of Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_installers = train_df1[\"installer_bkt\"].value_counts().nlargest(10).index\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(data=train_df1[train_df1[\"installer_bkt\"].isin(top_funders)], x=\"installer_bkt\", hue=\"status_group\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Functionality by Top Installers\", fontsize=16)\n",
    "plt.xlabel(\"Top 10 Installers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: “Other” dominates. Known installers (Hesawa, World Vision, Danida) show a mix of outcomes, but generally better than “other”.\n",
    "\n",
    "**Interpretation**: Standardizing approved installers could reduce failure rates. Donors should vet contractors more carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3.3 Type of Payment by Functionality Status of Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(data=train_df1, x=\"payment_type\", hue=\"status_group\")\n",
    "plt.title(\"Functionality by Type of Payment\", fontsize=16)\n",
    "plt.xlabel(\"Type of Payment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Wells where communities “never pay” show high non-functionality. Monthly and per-bucket payments are associated with higher functionality.\n",
    "\n",
    "**Interpretation**: Sustainable financing mechanisms (user contributions) are strongly linked to reliable water systems. Donors and government should encourage structured payment models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 Correlation Heatmap \n",
    "\n",
    "Shows the numeric feature relationships with the target variable which is the functionality status of the wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(train_df1.corr(), annot=True, fmt=\".2f\", cmap= \"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap (Numeric Features)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: There are weak correlations between the numeric features other than the derived features.\n",
    "\n",
    "**Interpretation**: No single numeric variable alone drives outcomes suggesting that multi factor interactions are key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Relationship between management group, type of payment and functionality status of the wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab([train_df1[\"management_group\"], train_df1[\"payment_type\"]], train_df1[\"status_group\"], normalize=\"index\") * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "*User-groups (the majority category)*:\n",
    "\n",
    "- Show best functionality when communities contribute annually (~75% functional) or monthly (~68% functional).\n",
    "- “Never pay” wells drop sharply (only ~44% functional, nearly half non-functional).\n",
    "- “Unknown” payment type performs poorly (~42% functional).\n",
    "\n",
    "*Parastatal management*:\n",
    "\n",
    "- Perform strongly when payments are structured (annually ~76%, per bucket ~81%).\n",
    "- “Never pay” again shows lower functionality (~57%).\n",
    "\n",
    "*Commercial management*:\n",
    "\n",
    "- Outcomes are mixed — “per bucket” has higher reliability (~78%), but “never pay” is weakest (~43% functional).\n",
    "\n",
    "*Other/Unknown managers*:\n",
    "\n",
    "- Results vary widely, with “never pay” and “unknown” categories generally performing worse.\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "- Payment structures strongly influence well sustainability, across all management models.\n",
    "\n",
    "- User-groups and structured payments (annual/monthly) deliver the most sustainable outcomes.\n",
    "\n",
    "- Wells where communities never pay or payment is “unknown” have much higher rates of non-functionality.\n",
    "\n",
    "- Parastatal-managed wells perform relatively well under structured payment schemes, suggesting stronger oversight.\n",
    "\n",
    "#### Business Takeaway\n",
    "\n",
    "A well’s sustainability is not just about who manages it, but also how payment is structured.\n",
    "\n",
    "For NGOs, donors, and government:\n",
    "\n",
    "1. Strengthen user-group governance with structured payments.\n",
    "\n",
    "2. Avoid “free water” models — they correlate with higher breakdown rates.\n",
    "\n",
    "3. Encourage annual or per-bucket contributions, especially for parastatal and commercial management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Relationship  between Age of Well, Type of Waterpoint and Functionality Status of Wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(data=train_df1, x=\"waterpoint_type_group\", y=\"age_years\", hue=\"status_group\")\n",
    "plt.title(\"Age vs Waterpoint Type and Functionality\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "*Communal standpipes*: Functional wells tend to be younger. Many non-functional ones are clustered at higher ages (15+ years).\n",
    "\n",
    "*Hand pumps*: Distribution is younger compared to communal standpipes. Non-functional hand pumps appear more evenly spread across ages.\n",
    "\n",
    "*Other types*: Wide spread in ages, with many non-functional wells even at younger ages.\n",
    "\n",
    "*Improved springs & cattle troughs*: Generally younger; functionality is relatively stable.\n",
    "\n",
    "*Dams*: Fewer data points, but many are older and still functional, though variability is high.\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "Age clearly influences functionality, but the effect varies by technology:\n",
    "\n",
    "- Communal standpipes show clear aging-related failures → they degrade faster.\n",
    "- Hand pumps are more resilient across ages but still have significant failures.\n",
    "- Improved springs seem relatively reliable even as they age.\n",
    "- Dams are rare but appear to last longer when maintained.\n",
    "\n",
    "This interaction suggests that maintenance priorities should differ by waterpoint type:\n",
    "\n",
    "*Standpipes*: higher priority for preventive repairs as they age.\n",
    "\n",
    "*Hand pumps*: more evenly distributed → failure may be linked to management, not just age.\n",
    "\n",
    "*Springs/dams*: appear more durable, but limited coverage.\n",
    "\n",
    "**Business takeaway**: Technology choice and age jointly predict functionality. Maintenance schedules should not be uniform; instead, tailor based on both age and type of waterpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=train_df1, x=\"population\", y=\"age_years\", hue=\"status_group\", style=\"waterpoint_type_group\", alpha=0.6)\n",
    "plt.title(\"Population Stress and Age by Waterpoint Type\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab([train_df1[\"region_zone\"], train_df1[\"source_class\"]], train_df1[\"status_group\"], normalize=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "*Groundwater*:\n",
    "\n",
    "- Performs best in the Northern Highlands (~64% functional) and Southern Highlands (~61%).\n",
    "- Weakest in Coastal (43%) and Central zone (46%), where non-functional rates are higher.\n",
    "\n",
    "*Surface water*:\n",
    "\n",
    "- In the Central zone, surface water is relatively functional (~63%), better than groundwater.\n",
    "- In the Coastal and Lake Basin, surface water performs worse (high non-functionality ~32–49%).\n",
    "\n",
    "*Unknown source class*:\n",
    "\n",
    "- Generally unreliable, with very high non-functionality (e.g., 83% in Central, 75% in Lake Basin).\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "- Groundwater reliability is highly regional: better in the Highlands, worse in Coastal/Central areas (possibly due to salinity, water table depth, or geology).\n",
    "- Surface water reliability varies: more functional in Central, but less so in Coastal and Lake Basin where contamination/flooding are likely issues.\n",
    "- Unknown source classification indicates poor records or unclear construction — strongly correlated with failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Hypothesis Testing\n",
    "\n",
    "In this section, we statistically test whether key factors identified in EDA \n",
    "(financing, governance, technical, and environmental) are significantly associated \n",
    "with well functionality.\n",
    "\n",
    "We use:\n",
    "- **Chi-Square Test of Independence** for categorical variables vs functionality.\n",
    "- **ANOVA (Analysis of Variance)** for numeric vs functionality groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Payment Type vs Functionality\n",
    "\n",
    "**Hypothesis**  \n",
    "- H₀: Well functionality is independent of payment type.  \n",
    "- H₁: Well functionality is associated with payment type.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(train_df1[\"payment_type\"], train_df1[\"status_group\"])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "print(\"Chi2:\", chi2, \"p-value:\", p)\n",
    "\n",
    "if p < 0.05:\n",
    "    print(\"✅ Reject H₀: Payment type significantly affects functionality.\")\n",
    "else:\n",
    "    print(\"❌ Fail to reject H₀: No significant association.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 Management Group vs Functionality\n",
    "**Hypothesis**  \n",
    "- H₀: Well functionality is independent of management group.  \n",
    "- H₁: Well functionality depends on management group.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(train_df1[\"management_group\"], train_df1[\"status_group\"])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "print(\"Chi2:\", chi2, \"p-value:\", p)\n",
    "\n",
    "if p < 0.05:\n",
    "    print(\"✅ Reject H₀: Management group significantly affects functionality.\")\n",
    "else:\n",
    "    print(\"❌ Fail to reject H₀: No significant association.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 Age of Wells vs Functionality(ANOVA)\n",
    "**Hypothesis**  \n",
    "- H₀: The average age of wells is the same across all functionality groups.  \n",
    "- H₁: At least one functionality group has a significantly different average age.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_stat, p = f_oneway(\n",
    "    train_df1.loc[train_df1[\"status_group\"]==\"functional\", \"age_years\"],\n",
    "    train_df1.loc[train_df1[\"status_group\"]==\"non functional\", \"age_years\"],\n",
    "    train_df1.loc[train_df1[\"status_group\"]==\"functional needs repair\", \"age_years\"]\n",
    ")\n",
    "print(\"ANOVA F:\", f_stat, \"p-value:\", p)\n",
    "\n",
    "if p < 0.05:\n",
    "    print(\"✅ Reject H₀: Well age significantly differs across functionality groups.\")\n",
    "else:\n",
    "    print(\"❌ Fail to reject H₀: No significant difference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4 Region Zone by Source Class vs Functionality\n",
    "**Hypothesis**  \n",
    "- H₀: Well functionality is independent of source class within regions.  \n",
    "- H₁: Functionality significantly depends on source class across regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab([train_df1[\"region_zone\"], train_df1[\"source_class\"]], train_df1[\"status_group\"])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "print(\"Chi2:\", chi2, \"p-value:\", p)\n",
    "\n",
    "if p < 0.05:\n",
    "    print(\"✅ Reject H₀: Region × Source class significantly affects functionality.\")\n",
    "else:\n",
    "    print(\"❌ Fail to reject H₀: No significant association.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.5 Extraction Type vs Functionality\n",
    "**Hypothesis**  \n",
    "- H₀: Well functionality is independent of extraction type.  \n",
    "- H₁: Well functionality depends on extraction type.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(train_df1[\"extraction_type_class\"], train_df1[\"status_group\"])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "print(\"Chi2:\", chi2, \"p-value:\", p)\n",
    "\n",
    "if p < 0.05:\n",
    "    print(\"✅ Reject H₀: Extraction type significantly affects functionality.\")\n",
    "else:\n",
    "    print(\"❌ Fail to reject H₀: No significant association.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The hypothesis testing results confirm that key factors such as **payment type, management model, age of wells, extraction technology, and regional source class** are significantly associated with well functionality. These findings validate the patterns identified during EDA and highlight the importance of both **technical features (age, extraction type)** and **socio-governance factors (payment, management)** in predicting sustainability.\n",
    "\n",
    "With these insights, we now move to the **modeling phase**, where the goal is to build predictive models that can classify wells into *functional, needs repair, or non-functional* categories. By incorporating the most significant features identified in EDA and hypothesis testing, the models will not only aim for high predictive accuracy, but also provide **interpretable outputs** that can guide stakeholders in **prioritizing maintenance, allocating resources, and planning new well installations**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modeling\n",
    "\n",
    "The objective of the modeling phase is to build predictive models that can classify wells into one of three categories:\n",
    "- **Functional**\n",
    "- **Functional needs repair**\n",
    "- **Non-functional**\n",
    "\n",
    "This task is a **multi-class classification problem**.\n",
    "\n",
    "Key considerations:\n",
    "- The dataset is **imbalanced** (majority functional, fewer \"needs repair\").\n",
    "- Features include a mix of **categorical (e.g., management_group, payment_type)** and **numerical (e.g., age_years, gps_height, population_log)** variables.\n",
    "- The modeling approach must balance **predictive performance** with **interpretability**, ensuring that outputs can provide actionable insights to stakeholders such as the Government of Tanzania, NGOs, and donors.\n",
    "\n",
    "The goals of modeling are therefore:\n",
    "1. Achieve strong predictive accuracy (≥70%) on unseen data.\n",
    "2. Identify the most important predictors of well functionality.\n",
    "3. Provide interpretable insights that can guide **maintenance prioritization** and **policy decisions**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the cleaned df\n",
    "train = train_df1.copy()\n",
    "test = test_df1.copy()\n",
    "\n",
    "# preview the dataframe\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transform amount tsh\n",
    "train[\"amount_tsh_log\"] = np.log1p(train[\"amount_tsh\"])\n",
    "test[\"amount_tsh_log\"] = np.log1p(test[\"amount_tsh\"])\n",
    "\n",
    "#log transform population\n",
    "train[\"population_log\"] = np.log1p(train[\"population\"])\n",
    "test[\"population_log\"] = np.log1p(test[\"population\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features to keep\n",
    "features = [\"gps_height\", \"age_years\", \"amount_tsh_log\",\"population_log\", \n",
    "            \"funder_bkt\",\"installer_bkt\", \"basin\", \"region_zone\", \n",
    "            \"scheme_management\", \"management_group\", \"payment_type\",\n",
    "            \"quality_group\", \"quantity_group\", \"source_class\",\n",
    "            \"waterpoint_type_group\", \"permit\", \"public_meeting\"]\n",
    "\n",
    "# get the test and train sets\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[\"status_group\"]\n",
    "X_test = test[features]\n",
    "\n",
    "print(\"Final feature set prepared:\")\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Features used:\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "\n",
    "cat_cols = X_train.select_dtypes(include=\"object\").columns\n",
    "\n",
    "X_train_ohe = pd.get_dummies(X_train, columns = cat_cols, drop_first=True, dtype=int)\n",
    "X_test_ohe = pd.get_dummies(X_test, columns = cat_cols, drop_first=True, dtype=int)\n",
    "\n",
    "print(\"Encoded dataframe created:\")\n",
    "print(\"Train shape:\", X_train_ohe.shape)\n",
    "print(\"Test shape:\", X_test_ohe.shape)\n",
    "\n",
    "# align the columns\n",
    "X_train_ohe, X_test_ohe = X_train_ohe.align(X_test_ohe, join=\"left\", axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train data into training set and validation set\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_ohe, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "#check shape\n",
    "X_train_split.shape, X_val_split.shape, y_train_split.shape, y_val_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numeric features (for Logistic Regression)\n",
    "num_cols = X_train_split.columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_split[num_cols] = scaler.fit_transform(X_train_split[num_cols])\n",
    "X_val_split[num_cols] = scaler.transform(X_val_split[num_cols])\n",
    "X_test_ohe[num_cols] = scaler.transform(X_test_ohe[num_cols]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_split = y_train_split.astype(\"category\")\n",
    "y_val_split = y_val_split.astype(\"category\")\n",
    "\n",
    "y_train_split = y_train_split.cat.codes\n",
    "y_val_split = y_val_split.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SMOTE to help with class imbalance\n",
    "smoten = SMOTEN(random_state=42)\n",
    "\n",
    "# Apply to training split\n",
    "X_train_res, y_train_res = smoten.fit_resample(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model(Logistic Regression)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training score\n",
    "print(f\"The model score on training data is: {lr.score(X_train_split, y_train_split)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on training data\n",
    "y_pred = lr.predict(X_val_split)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val_split, y_pred)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf = confusion_matrix(y_val_split, y_pred, labels=lr.classes_)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=lr.classes_, yticklabels=lr.classes_)\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "1. *Strong detection of functional wells*\n",
    "\n",
    "The model correctly identified most functional wells (5,774), showing that it is reliable at recognizing wells that are in working condition.\n",
    "\n",
    "2. *Weak performance on “needs repair” wells*\n",
    "\n",
    "Out of all wells that truly needed repair, only 52 were correctly predicted.\n",
    "The majority were misclassified as functional (629) or non-functional (182).\n",
    "This indicates that the model struggles to capture the minority class, likely due to class imbalance.\n",
    "\n",
    "3. *Risk of false positives (critical issue)*\n",
    "\n",
    "1,720 non-functional wells were misclassified as functional.\n",
    "This is highly problematic in practice because it means communities with broken wells would be assumed to have access to water.\n",
    "\n",
    "4. *Better detection of fully broken wells*\n",
    "\n",
    "The model correctly predicted 2,814 non-functional wells, but the high number of misclassifications into \"functional\" highlights the need for improvement.\n",
    "\n",
    "**Overall conclusion**\n",
    "\n",
    "The model is biased toward predicting \"functional\" and underrepresents the “needs repair” and “non-functional” categories.\n",
    "\n",
    "While accuracy might look acceptable, the recall for broken wells is low, which is not aligned with our goal of minimizing false positives. There is therefore need to handle class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report \n",
    "print(classification_report(y_val_split, y_pred, target_names=lr.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "- The Logistic Regression baseline achieves an overall accuracy of 73%, but the performance across classes is uneven. \n",
    "- Functional wells are well captured (recall of 0.89), but both \"non-functional\" (recall of 0.62) and especially \"functional needs repair\" (recall of 0.06) are poorly detected. This reflects the impact of class imbalance, as the model is heavily biased toward predicting wells as functional. \n",
    "- Critically, the high number of false positives — cases where broken wells are predicted as functional — undermines the usefulness of this model for real-world deployment. \n",
    "- These results highlight the need for more advanced models (Random Forest, XGBoost) and imbalance handling strategies to improve recall for wells that are broken or need repair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
